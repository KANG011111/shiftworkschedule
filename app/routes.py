from flask import Blueprint, render_template, request, jsonify, redirect, url_for, g, flash, session
from app.models import db, Employee, ShiftType, Schedule, User, ImportLog
from app.auth_middleware import require_auth, require_admin, optional_auth, get_current_user
from datetime import datetime, date
import pandas as pd
import json
import hashlib
import re
import os

main = Blueprint('main', __name__)

@main.route('/')
@require_auth
def index():
    current_user = get_current_user()
    
    today = date.today()
    
    # æŒ‡å®šçš„å“¡å·¥åå–®ï¼ˆé…åˆè³‡æ–™åº«ä¸­çš„ç©ºæ ¼æ ¼å¼ï¼‰
    target_employees = [
        'è³´ ç§‰ å®', 'æ æƒŸ ç¶±', 'æ å®¶ ç‘‹', 'ç‹ å¿— å¿ ', 'é¡§ è‚² ç¦', 
        'èƒ¡ ç¿Š æ½”', 'æœ± å®¶ å¾·', 'é™³ éŸ‹ å¦‚', 'è‘› ç¦', 'äº• åº· ç¾½', 
        'ç°¡ èŠ³ ç‘œ', 'æ¢ å¼˜ å²³', 'æ ä½© ç’‡', 'é„­ æ ¢ ç”', 'ç‹ æ–‡ æ€¡'
    ]
    
    today_schedules = Schedule.query.join(Employee).filter(
        Schedule.date == today,
        Employee.name.in_(target_employees)
    ).all()
    
    return render_template('index.html', today_schedules=today_schedules, today=today)

# ç§»é™¤å“¡å·¥ç®¡ç†åŠŸèƒ½ï¼Œåªä¿ç•™å€‹äººç­è¡¨æŸ¥çœ‹
# @main.route('/employees')
# @main.route('/add_employee', methods=['POST'])

@main.route('/calendar')
@require_auth
def calendar():
    return render_template('calendar.html')

@main.route('/api/events')
@require_auth
def get_events():
    start_date = request.args.get('start')
    end_date = request.args.get('end')
    
    # å¦‚æœæ²’æœ‰æä¾›æ—¥æœŸåƒæ•¸ï¼Œä½¿ç”¨é è¨­ç¯„åœ
    if not start_date or not end_date:
        start_date = '2024-07-01'
        end_date = '2024-07-31'
    
    # æŒ‡å®šçš„å“¡å·¥åå–®
    target_employees = [
        'è³´ç§‰å®', 'ææƒŸç¶±', 'æå®¶ç‘‹', 'ç‹å¿—å¿ ', 'é¡§è‚²ç¦', 
        'èƒ¡ç¿Šæ½”', 'æœ±å®¶å¾·', 'é™³éŸ‹å¦‚', 'è‘›ç¦', 'äº•åº·ç¾½', 
        'ç°¡èŠ³ç‘œ', 'æ¢å¼˜å²³', 'æä½©ç’‡', 'é„­æ ¢ç”', 'ç‹æ–‡æ€¡'
    ]
    
    try:
        schedules = Schedule.query.join(Employee).filter(
            Schedule.date >= datetime.strptime(start_date, '%Y-%m-%d').date(),
            Schedule.date <= datetime.strptime(end_date, '%Y-%m-%d').date(),
            Employee.name.in_(target_employees)
        ).all()
        
        events = []
        
        # æŒ‰æ—¥æœŸåˆ†çµ„äº‹ä»¶ï¼Œé¿å…å¤ªå¤šé‡ç–Š
        from collections import defaultdict
        daily_events = defaultdict(list)
        
        for schedule in schedules:
            daily_events[schedule.date].append(schedule)
        
        # ç‚ºæ¯ä¸€å¤©å‰µå»ºäº‹ä»¶
        for schedule_date, day_schedules in daily_events.items():
            if len(day_schedules) <= 3:
                # å¦‚æœç•¶å¤©æ’ç­äººæ•¸å°‘ï¼Œé¡¯ç¤ºå€‹åˆ¥äº‹ä»¶
                for schedule in day_schedules:
                    events.append({
                        'id': f"single_{schedule.id}",
                        'title': f"{schedule.employee.name}({schedule.shift_type.code})",
                        'start': schedule_date.isoformat(),
                        'backgroundColor': schedule.shift_type.color,
                        'borderColor': schedule.shift_type.color,
                        'textColor': '#fff',
                        'extendedProps': {
                            'employee': schedule.employee.name,
                            'shift': schedule.shift_type.name,
                            'shift_code': schedule.shift_type.code,
                            'type': 'single'
                        }
                    })
            else:
                # å¦‚æœç•¶å¤©æ’ç­äººæ•¸å¤šï¼Œé¡¯ç¤ºå½™ç¸½äº‹ä»¶
                shift_summary = {}
                for schedule in day_schedules:
                    shift_code = schedule.shift_type.code
                    if shift_code not in shift_summary:
                        shift_summary[shift_code] = {
                            'count': 0,
                            'color': schedule.shift_type.color,
                            'employees': []
                        }
                    shift_summary[shift_code]['count'] += 1
                    shift_summary[shift_code]['employees'].append(schedule.employee.name)
                
                # ç‚ºæ¯å€‹ç­åˆ¥å‰µå»ºä¸€å€‹äº‹ä»¶
                for shift_code, info in shift_summary.items():
                    events.append({
                        'id': f"summary_{schedule_date}_{shift_code}",
                        'title': f"{shift_code}ç­ ({info['count']}äºº)",
                        'start': schedule_date.isoformat(),
                        'backgroundColor': info['color'],
                        'borderColor': info['color'],
                        'textColor': '#fff',
                        'extendedProps': {
                            'employees': info['employees'],
                            'shift_code': shift_code,
                            'count': info['count'],
                            'type': 'summary',
                            'date': schedule_date.isoformat()
                        }
                    })
        
        return jsonify(events)
        
    except Exception as e:
        print(f"Events API éŒ¯èª¤: {e}")
        return jsonify([]), 500

@main.route('/query_shift')
@require_auth
def query_shift():
    query_date = request.args.get('date')
    schedules = []
    
    # æŒ‡å®šçš„å“¡å·¥åå–®ï¼ˆåŒ…å«ç©ºæ ¼æ ¼å¼ï¼‰
    target_employees = [
        'è³´ ç§‰ å®', 'æ æƒŸ ç¶±', 'æ å®¶ ç‘‹', 'ç‹ å¿— å¿ ', 'é¡§ è‚² ç¦', 
        'èƒ¡ ç¿Š æ½”', 'æœ± å®¶ å¾·', 'é™³ éŸ‹ å¦‚', 'è‘› ç¦', 'äº• åº· ç¾½', 
        'ç°¡ èŠ³ ç‘œ', 'æ¢ å¼˜ å²³', 'æ ä½© ç’‡', 'é„­ æ ¢ ç”', 'ç‹ æ–‡ æ€¡'
    ]
    
    if query_date:
        try:
            target_date = datetime.strptime(query_date, '%Y-%m-%d').date()
            schedules = Schedule.query.join(Employee).filter(
                Schedule.date == target_date,
                Employee.name.in_(target_employees)
            ).all()
        except ValueError:
            query_date = None
    
    return render_template('query.html', query_date=query_date, schedules=schedules)

@main.route('/api/query_shift')
@require_auth
def api_query_shift():
    query_date = request.args.get('date')
    
    # æŒ‡å®šçš„å“¡å·¥åå–®ï¼ˆåŒ…å«ç©ºæ ¼æ ¼å¼ï¼‰
    target_employees = [
        'è³´ ç§‰ å®', 'æ æƒŸ ç¶±', 'æ å®¶ ç‘‹', 'ç‹ å¿— å¿ ', 'é¡§ è‚² ç¦', 
        'èƒ¡ ç¿Š æ½”', 'æœ± å®¶ å¾·', 'é™³ éŸ‹ å¦‚', 'è‘› ç¦', 'äº• åº· ç¾½', 
        'ç°¡ èŠ³ ç‘œ', 'æ¢ å¼˜ å²³', 'æ ä½© ç’‡', 'é„­ æ ¢ ç”', 'ç‹ æ–‡ æ€¡'
    ]
    
    if query_date:
        target_date = datetime.strptime(query_date, '%Y-%m-%d').date()
        schedules = Schedule.query.join(Employee).filter(
            Schedule.date == target_date,
            Employee.name.in_(target_employees)
        ).all()
        
        result = []
        for schedule in schedules:
            result.append({
                'employee': schedule.employee.name,
                'shift': schedule.shift_type.name,
                'shift_code': schedule.shift_type.code,
                'color': schedule.shift_type.color
            })
        
        return jsonify(result)
    
    return jsonify([])



@main.route('/api/employees')
def api_employees():
    search_term = request.args.get('q', '').strip()
    
    # æœå°‹æœ‰ç­è¡¨è³‡æ–™çš„å“¡å·¥
    query = Employee.query.join(Schedule).distinct()
    
    if search_term:
        query = query.filter(
            (Employee.name.contains(search_term)) |
            (Employee.employee_code.contains(search_term))
        )
    
    employees = query.limit(20).all()
    
    result = [{'id': emp.id, 'name': emp.name, 'code': emp.employee_code} for emp in employees]
    return jsonify(result)

@main.route('/api/shift_types')
def api_shift_types():
    shift_types = ShiftType.query.all()
    result = [{'code': st.code, 'name': st.name, 'color': st.color} for st in shift_types]
    return jsonify(result)

@main.route('/api/date_range')
def api_date_range():
    """ç²å–è³‡æ–™åº«ä¸­å¯¦éš›çš„æ—¥æœŸç¯„åœï¼Œæ”¯æ´å¤šæœˆä»½"""
    first_schedule = Schedule.query.order_by(Schedule.date.asc()).first()
    last_schedule = Schedule.query.order_by(Schedule.date.desc()).first()
    
    if first_schedule and last_schedule:
        # ç²å–æ‰€æœ‰æœ‰è³‡æ–™çš„æ—¥æœŸ
        all_dates = [s.date.strftime('%Y-%m-%d') for s in Schedule.query.all()]
        unique_dates = sorted(list(set(all_dates)))
        
        # çµ±è¨ˆå„æœˆä»½çš„è³‡æ–™
        month_stats = {}
        for schedule in Schedule.query.all():
            year_month = f'{schedule.date.year}-{schedule.date.month:02d}'
            if year_month not in month_stats:
                month_stats[year_month] = {
                    'count': 0,
                    'year': schedule.date.year,
                    'month': schedule.date.month,
                    'display': f'{schedule.date.year}å¹´{schedule.date.month:02d}æœˆ'
                }
            month_stats[year_month]['count'] += 1
        
        # å¦‚æœè·¨æœˆä»½ï¼Œé¡¯ç¤ºç¯„åœï¼›å¦‚æœåŒæœˆä»½ï¼Œé¡¯ç¤ºå–®æœˆ
        if first_schedule.date.month == last_schedule.date.month and first_schedule.date.year == last_schedule.date.year:
            month_display = first_schedule.date.strftime('%Yå¹´%mæœˆ')
        else:
            month_display = f'{first_schedule.date.strftime("%Yå¹´%mæœˆ")} è‡³ {last_schedule.date.strftime("%Yå¹´%mæœˆ")}'
        
        return jsonify({
            'start_date': first_schedule.date.strftime('%Y-%m-%d'),
            'end_date': last_schedule.date.strftime('%Y-%m-%d'),
            'month_year': month_display,
            'year': first_schedule.date.year,
            'month': first_schedule.date.month,
            'available_dates': unique_dates,
            'available_months': month_stats
        })
    else:
        return jsonify({
            'start_date': '2025-07-01',
            'end_date': '2025-07-31',
            'month_year': '2025å¹´07æœˆ',
            'year': 2025,
            'month': 7,
            'available_dates': [],
            'available_months': {}
        })

@main.route('/export_schedule')
@require_auth
def export_schedule():
    """ä¸€éµåŒ¯å‡ºæœˆåº¦ç­è¡¨é é¢"""
    return render_template('export.html')

@main.route('/api/preview_schedule')
def api_preview_schedule():
    """æä¾›ç­è¡¨é è¦½è³‡æ–™çµ¦å‰ç«¯ç”ŸæˆJPG"""
    try:
        # å–å¾—æŸ¥è©¢åƒæ•¸
        search_query = request.args.get('query', '').strip()
        year = request.args.get('year', type=int)
        month = request.args.get('month', type=int)
        
        if not search_query:
            return jsonify({'error': 'è«‹è¼¸å…¥å“¡å·¥å§“åæˆ–å·¥è™Ÿ'}), 400
            
        if not year or not month:
            return jsonify({'error': 'è«‹é¸æ“‡å¹´æœˆ'}), 400
            
        # ç¢ºä¿æ¸¬è©¦å“¡å·¥å­˜åœ¨
        from app.models import db
        employee_data = [
            ('è³´ ç§‰ å®', '8652'),
            ('æ æƒŸ ç¶±', '8312'), 
            ('æ å®¶ ç‘‹', '8512'),
            ('ç‹ å¿— å¿ ', '0450'),
            ('é¡§ è‚² ç¦', '8672'),
            ('èƒ¡ ç¿Š æ½”', '8619'),
            ('æœ± å®¶ å¾·', '8835')
        ]
        
        # æ¯æ¬¡è«‹æ±‚æ™‚ç¢ºä¿å“¡å·¥å­˜åœ¨ï¼ˆè¨˜æ†¶é«”è³‡æ–™åº«éœ€è¦ï¼‰
        for name, code in employee_data:
            employee = Employee.query.filter_by(name=name).first()
            if not employee:
                employee = Employee(name=name, employee_code=code)
                db.session.add(employee)
        db.session.commit()
        
        # æœå°‹å“¡å·¥ï¼ˆæ”¯æ´å§“åæ¨¡ç³Šæœå°‹å’Œå®Œæ•´å§“åï¼‰
        employee = Employee.query.filter(
            Employee.name.like(f'%{search_query}%')
        ).first()
        
        # å¦‚æœæ¨¡ç³Šæœå°‹æ‰¾ä¸åˆ°ï¼Œå˜—è©¦ç²¾ç¢ºåŒ¹é…
        if not employee:
            employee = Employee.query.filter_by(name=search_query).first()
        
        # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œå˜—è©¦ç§»é™¤ç©ºæ ¼çš„åŒ¹é…
        if not employee:
            search_no_space = search_query.replace(' ', '')
            for emp in Employee.query.all():
                if emp.name.replace(' ', '') == search_no_space:
                    employee = emp
                    break
        
        if not employee:
            return jsonify({'error': f'æ‰¾ä¸åˆ°å“¡å·¥: {search_query}'}), 404
            
        # å–å¾—è©²å“¡å·¥çš„æœˆåº¦æ’ç­è³‡æ–™
        from datetime import date
        import calendar
        
        start_date = date(year, month, 1)
        last_day = calendar.monthrange(year, month)[1]
        end_date = date(year, month, last_day)
        
        schedules = Schedule.query.filter(
            Schedule.employee_id == employee.id,
            Schedule.date >= start_date,
            Schedule.date <= end_date
        ).order_by(Schedule.date.asc()).all()
        
        # å…è¨±é¡¯ç¤ºéƒ¨åˆ†è³‡æ–™æˆ–ç©ºç™½æœˆæ›†ï¼Œä¸å†è¦æ±‚å¿…é ˆæœ‰å®Œæ•´è³‡æ–™
        # if not schedules:
        #     return jsonify({'error': f'{employee.name} åœ¨ {year}å¹´{month:02d}æœˆ æ²’æœ‰æ’ç­è³‡æ–™'}), 404
            
        # å»ºç«‹æœˆæ›†çµæ§‹
        cal = calendar.monthcalendar(year, month)
        
        # æº–å‚™æ’ç­è³‡æ–™
        schedule_data = []
        for schedule in schedules:
            schedule_data.append({
                'date': schedule.date.isoformat(),
                'shift_code': schedule.shift_type.code,
                'shift_name': schedule.shift_type.name
            })
        
        # æº–å‚™å›å‚³è³‡æ–™
        response_data = {
            'employee': {
                'name': employee.name,
                'employee_code': employee.employee_code
            },
            'year': year,
            'month': month,
            'schedules': schedule_data,
            'calendar': cal
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        print(f'é è¦½APIéŒ¯èª¤: {e}')
        return jsonify({'error': str(e)}), 500

@main.route('/api/export_monthly_schedule')
def api_export_monthly_schedule():
    """åŒ¯å‡ºæŒ‡å®šå“¡å·¥çš„æœˆåº¦ç­è¡¨ç‚ºExcel"""
    try:
        # å–å¾—æŸ¥è©¢åƒæ•¸
        search_query = request.args.get('query', '').strip()
        year = request.args.get('year', type=int)
        month = request.args.get('month', type=int)
        
        if not search_query:
            return jsonify({'error': 'è«‹è¼¸å…¥å“¡å·¥å§“åæˆ–å·¥è™Ÿ'}), 400
            
        if not year or not month:
            return jsonify({'error': 'è«‹é¸æ“‡å¹´æœˆ'}), 400
            
        # æœå°‹å“¡å·¥ï¼ˆæ”¯æ´å§“åæˆ–å“¡å·¥ä»£ç¢¼ï¼‰
        employee = Employee.query.filter(
            (Employee.name.like(f'%{search_query}%')) |
            (Employee.employee_code.like(f'%{search_query}%'))
        ).first()
        
        if not employee:
            return jsonify({'error': f'æ‰¾ä¸åˆ°å“¡å·¥: {search_query}'}), 404
            
        # å–å¾—è©²å“¡å·¥çš„æœˆåº¦æ’ç­è³‡æ–™
        from datetime import date
        start_date = date(year, month, 1)
        
        # è¨ˆç®—æœˆä»½çš„æœ€å¾Œä¸€å¤©
        import calendar
        last_day = calendar.monthrange(year, month)[1]
        end_date = date(year, month, last_day)
        
        schedules = Schedule.query.filter(
            Schedule.employee_id == employee.id,
            Schedule.date >= start_date,
            Schedule.date <= end_date
        ).order_by(Schedule.date.asc()).all()
        
        if not schedules:
            return jsonify({'error': f'{employee.name} åœ¨ {year}å¹´{month:02d}æœˆ æ²’æœ‰æ’ç­è³‡æ–™'}), 404
            
        # å»ºç«‹æœˆæ›†å¼ExcelåŒ¯å‡º
        import pandas as pd
        from io import BytesIO
        import calendar
        from openpyxl import Workbook
        from openpyxl.styles import Font, PatternFill, Border, Side, Alignment
        
        # å»ºç«‹å·¥ä½œç°¿
        wb = Workbook()
        ws = wb.active
        ws.title = 'æœˆåº¦ç­è¡¨'
        
        # è¨­å®šæ¨™é¡Œ
        ws['A1'] = f'{employee.name} å€‹äººç­è¡¨'
        ws['A2'] = f'å·¥è™Ÿ: {employee.employee_code}'
        ws['A3'] = f'{year}å¹´{month:02d}æœˆ'
        
        # åˆä½µæ¨™é¡Œå„²å­˜æ ¼
        ws.merge_cells('A1:H1')
        ws.merge_cells('A2:H2')
        ws.merge_cells('A3:H3')
        
        # è¨­å®šæ¨™é¡Œæ¨£å¼
        title_font = Font(name='å¾®è»Ÿæ­£é»‘é«”', size=16, bold=True)
        subtitle_font = Font(name='å¾®è»Ÿæ­£é»‘é«”', size=12)
        ws['A1'].font = title_font
        ws['A2'].font = subtitle_font
        ws['A3'].font = subtitle_font
        ws['A1'].alignment = Alignment(horizontal='center')
        ws['A2'].alignment = Alignment(horizontal='center')
        ws['A3'].alignment = Alignment(horizontal='center')
        
        # å»ºç«‹ç­è¡¨è³‡æ–™å­—å…¸
        schedule_dict = {}
        for schedule in schedules:
            schedule_dict[schedule.date.day] = schedule.shift_type.code
        
        # å–å¾—è©²æœˆçš„æ—¥æ›†è³‡è¨Š
        cal = calendar.monthcalendar(year, month)
        weekdays = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']
        
        # å¾ç¬¬5è¡Œé–‹å§‹å»ºç«‹æ—¥æ›†è¡¨æ ¼
        start_row = 5
        
        # å¯«å…¥æ˜ŸæœŸæ¨™é¡Œ
        for col, weekday in enumerate(weekdays, 1):
            cell = ws.cell(row=start_row, column=col, value=weekday)
            cell.font = Font(name='å¾®è»Ÿæ­£é»‘é«”', size=12, bold=True)
            cell.fill = PatternFill(start_color='D9E2F3', end_color='D9E2F3', fill_type='solid')
            cell.alignment = Alignment(horizontal='center')
            
        # è¨­å®šé‚Šæ¡†æ¨£å¼
        thin_border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        # å¡«å…¥æ—¥æœŸå’Œç­åˆ¥
        for week_num, week in enumerate(cal):
            row = start_row + 1 + week_num
            for day_num, day in enumerate(week, 1):
                if day == 0:  # ç©ºç™½æ—¥æœŸ
                    cell = ws.cell(row=row, column=day_num, value='')
                else:
                    # æ—¥æœŸ
                    date_str = str(day)
                    # ç­åˆ¥ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
                    shift_code = schedule_dict.get(day, '')
                    
                    if shift_code:
                        cell_value = f'{date_str}\n{shift_code}'
                        # è¨­å®šç­åˆ¥èƒŒæ™¯è‰²
                        if 'H' in shift_code:  # ä¼‘å‡
                            fill_color = 'FFE6CC'  # æ·ºæ©™è‰²
                        elif 'P1' in shift_code:  # P1ç­
                            fill_color = 'E2EFDA'  # æ·ºç¶ è‰²
                        elif 'P2' in shift_code:  # P2ç­
                            fill_color = 'FFF2CC'  # æ·ºé»ƒè‰²
                        elif 'P3' in shift_code:  # P3ç­
                            fill_color = 'FCE4D6'  # æ·ºæ©™è‰²
                        elif 'P4' in shift_code:  # P4ç­
                            fill_color = 'F4CCCC'  # æ·ºç´…è‰²
                        elif 'FC' in shift_code:  # FCç­
                            fill_color = 'D0E0E3'  # æ·ºè—è‰²
                        else:
                            fill_color = 'F2F2F2'  # æ·ºç°è‰²
                        
                        cell = ws.cell(row=row, column=day_num, value=cell_value)
                        cell.fill = PatternFill(start_color=fill_color, end_color=fill_color, fill_type='solid')
                    else:
                        cell = ws.cell(row=row, column=day_num, value=date_str)
                        cell.fill = PatternFill(start_color='F8F9FA', end_color='F8F9FA', fill_type='solid')
                    
                    cell.font = Font(name='å¾®è»Ÿæ­£é»‘é«”', size=10)
                    cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # æ·»åŠ é‚Šæ¡†
                ws.cell(row=row, column=day_num).border = thin_border
        
        # ç‚ºæ˜ŸæœŸæ¨™é¡Œè¡Œä¹Ÿæ·»åŠ é‚Šæ¡†
        for col in range(1, 8):
            ws.cell(row=start_row, column=col).border = thin_border
        
        # è¨­å®šæ¬„ä½å¯¬åº¦
        for col in range(1, 8):
            ws.column_dimensions[chr(64 + col)].width = 12
        
        # è¨­å®šè¡Œé«˜
        for row in range(start_row + 1, start_row + 1 + len(cal)):
            ws.row_dimensions[row].height = 40
        
        # æ·»åŠ åœ–ä¾‹èªªæ˜
        legend_start_row = start_row + len(cal) + 2
        ws.cell(row=legend_start_row, column=1, value='ç­åˆ¥èªªæ˜:').font = Font(name='å¾®è»Ÿæ­£é»‘é«”', size=12, bold=True)
        
        # å–å¾—è©²å“¡å·¥ä½¿ç”¨çš„ç­åˆ¥é¡å‹
        used_shift_types = set()
        for schedule in schedules:
            used_shift_types.add((schedule.shift_type.code, schedule.shift_type.name))
        
        legend_row = legend_start_row + 1
        for i, (code, name) in enumerate(sorted(used_shift_types)):
            legend_cell = ws.cell(row=legend_row + i, column=1, value=f'{code}: {name}')
            legend_cell.font = Font(name='å¾®è»Ÿæ­£é»‘é«”', size=10)
        
        # ä¿å­˜åˆ°BytesIO
        output = BytesIO()
        wb.save(output)
            
        output.seek(0)
        
        # æº–å‚™æª”æ¡ˆåç¨±
        filename = f'{employee.name}_{year}å¹´{month:02d}æœˆ_ç­è¡¨.xlsx'
        
        # è¿”å›æª”æ¡ˆä¸‹è¼‰
        from flask import send_file
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
        
    except Exception as e:
        print(f'åŒ¯å‡ºéŒ¯èª¤: {e}')
        return jsonify({'error': str(e)}), 500

@main.route('/upload_excel', methods=['GET', 'POST'])
@require_admin
def upload_excel():
    if request.method == 'POST':
        try:
            if 'file' not in request.files:
                return render_template('upload.html', error='è«‹é¸æ“‡æª”æ¡ˆ')
            
            file = request.files['file']
            if file.filename == '':
                return render_template('upload.html', error='è«‹é¸æ“‡æª”æ¡ˆ')
            
            if not file.filename.endswith('.csv'):
                return render_template('upload.html', error='åªæ”¯æ´ CSV æ ¼å¼æª”æ¡ˆ')
            
            print(f'é–‹å§‹è™•ç†æª”æ¡ˆ: {file.filename}')
            
            # å˜—è©¦ä¸åŒçš„æ–¹æ³•è®€å– Excel æª”æ¡ˆ
            df = None
            for header_row in [0, 1, 2, 3, 4, 5]:  # å˜—è©¦å‰6è¡Œä½œç‚ºæ¨™é¡Œè¡Œ
                try:
                    temp_df = pd.read_excel(file, header=header_row)
                    print(f'å˜—è©¦æ¨™é¡Œè¡Œ {header_row}: {list(temp_df.columns)[:10]}')  # åªé¡¯ç¤ºå‰10å€‹æ¬„ä½
                    
                    # æª¢æŸ¥æ˜¯å¦åŒ…å«æˆ‘å€‘éœ€è¦çš„æ¬„ä½
                    columns_str = '|'.join(str(col).lower() for col in temp_df.columns)
                    if any(keyword in columns_str for keyword in ['å§“å', 'å“¡å·¥', 'æ—¥æœŸ', 'ç­', 'æ™‚é–“']):
                        df = temp_df
                        print(f'âœ… åœ¨ç¬¬ {header_row} è¡Œæ‰¾åˆ°æœ‰æ•ˆæ¨™é¡Œ')
                        break
                except Exception as e:
                    print(f'æ¨™é¡Œè¡Œ {header_row} è®€å–å¤±æ•—: {e}')
                    continue
            
            if df is None:
                # å¦‚æœæ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆæ¨™é¡Œï¼Œä½¿ç”¨ç¬¬ä¸€è¡Œ
                df = pd.read_excel(file)
                print('âš ï¸ æœªæ‰¾åˆ°æ˜ç¢ºæ¨™é¡Œè¡Œï¼Œä½¿ç”¨é è¨­æ ¼å¼')
            
            print(f'æœ€çµ‚è®€å–åˆ° {len(df)} è¡Œæ•¸æ“š')
            print(f'æœ€çµ‚æ¬„ä½: {list(df.columns)}')
            
            processed_count = 0
            error_count = 0
            
            # åµæ¸¬æ©«å‘ç­è¡¨æ ¼å¼
            for index, row in df.iterrows():
                try:
                    # å°‹æ‰¾å“¡å·¥å§“åï¼ˆé€šå¸¸åœ¨ç¬¬3æˆ–ç¬¬4æ¬„ï¼‰
                    employee_name = None
                    for col_idx in [3, 2, 1, 0]:  # æª¢æŸ¥å¯èƒ½çš„å§“åæ¬„ä½
                        col_name = f'Unnamed: {col_idx}' if col_idx > 0 else 'Unnamed: 0'
                        if col_name in row and not pd.isna(row[col_name]):
                            name_value = str(row[col_name]).strip()
                            # æª¢æŸ¥æ˜¯å¦çœ‹èµ·ä¾†åƒå§“åï¼ˆåŒ…å«ä¸­æ–‡å­—ä¸”ä¸æ˜¯æ•¸å­—æˆ–ç­åˆ¥ä»£ç¢¼ï¼‰
                            if name_value and not name_value.isdigit() and len(name_value) >= 2 and 'ï¼ˆç•°å‹•å¾Œï¼‰' not in name_value:
                                # é€²ä¸€æ­¥æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆå§“åæ ¼å¼
                                if any('\u4e00' <= char <= '\u9fff' for char in name_value):  # åŒ…å«ä¸­æ–‡
                                    employee_name = name_value
                                    print(f'æ‰¾åˆ°å“¡å·¥å§“å: {employee_name} (ç¬¬ {index+1} è¡Œ)')
                                    break
                    
                    if not employee_name:
                        continue
                    
                    # è™•ç†æ©«å‘ç­è¡¨ï¼šæ¯å€‹æ¬„ä½ä»£è¡¨ä¸€å¤©çš„ç­åˆ¥
                    current_date = datetime(2025, 7, 1).date()  # 114å¹´7æœˆ = 2025å¹´7æœˆ
                    
                    for col_name, shift_value in row.items():
                        if col_name.startswith('Unnamed:') and not pd.isna(shift_value):
                            shift_code = str(shift_value).strip()
                            print(f'  æª¢æŸ¥æ¬„ä½ {col_name}: å€¼={shift_value} -> ç­åˆ¥ä»£ç¢¼={shift_code}')
                            
                            # éæ¿¾æ‰éç­åˆ¥ä»£ç¢¼çš„å€¼
                            if shift_code and shift_code not in ['nan', employee_name] and len(shift_code) <= 10:
                                # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ç­åˆ¥ä»£ç¢¼ - æ”¾å¯¬æ¢ä»¶
                                print(f'  æª¢æŸ¥ç­åˆ¥ä»£ç¢¼ {shift_code} æ˜¯å¦æœ‰æ•ˆ...')
                                # æ›´å¯¬é¬†çš„ç­åˆ¥ä»£ç¢¼é©—è­‰ï¼šåªè¦ä¸æ˜¯ç´”æ•¸å­—ä¸”é•·åº¦åˆç†
                                if (not shift_code.isdigit() and 
                                    len(shift_code) >= 1 and 
                                    shift_code not in ['nan', 'NaN', 'None', ''] and
                                    not shift_code.replace('.', '').isdigit()):
                                    print(f'  âœ… æ‰¾åˆ°æœ‰æ•ˆç­åˆ¥: {shift_code}')
                                    
                                    # æŸ¥è©¢ç¾æœ‰å“¡å·¥è¨˜éŒ„
                                    existing_employee = Employee.query.filter_by(name=employee_name).first()
                                    if not existing_employee:
                                        # ç”Ÿæˆå”¯ä¸€çš„å“¡å·¥ä»£ç¢¼
                                        existing_count = Employee.query.count()
                                        employee_code = f"EMP_{existing_count+1:03d}"
                                        
                                        # ç¢ºä¿ä»£ç¢¼å”¯ä¸€æ€§
                                        while Employee.query.filter_by(employee_code=employee_code).first():
                                            existing_count += 1
                                            employee_code = f"EMP_{existing_count+1:03d}"
                                        
                                        new_employee = Employee(name=employee_name, employee_code=employee_code)
                                        db.session.add(new_employee)
                                        try:
                                            db.session.commit()
                                        except Exception as e:
                                            db.session.rollback()
                                            existing_employee = Employee.query.filter_by(name=employee_name).first()
                                            if not existing_employee:
                                                raise e
                                    else:
                                        new_employee = existing_employee
                                    
                                    employee = new_employee if 'new_employee' in locals() else existing_employee
                                    
                                    # è™•ç†ç­åˆ¥é¡å‹
                                    shift_type = ShiftType.query.filter_by(code=shift_code).first()
                                    if not shift_type:
                                        shift_name, start_time, end_time, color = get_shift_info(shift_code)
                                        shift_type = ShiftType(
                                            code=shift_code, 
                                            name=shift_name, 
                                            start_time=start_time, 
                                            end_time=end_time,
                                            color=color
                                        )
                                        db.session.add(shift_type)
                                    
                                    # è¨ˆç®—å°æ‡‰çš„æ—¥æœŸï¼ˆä¾æ¬„ä½ä½ç½®æ¨ç®—ï¼‰
                                    col_num = int(col_name.split(': ')[1]) if ': ' in col_name else 0
                                    day_offset = col_num - 4  # å‡è¨­ç¬¬4æ¬„é–‹å§‹æ˜¯7/1
                                    if day_offset >= 0 and day_offset < 31:  # 7æœˆæœ‰31å¤©
                                        schedule_date = datetime(2025, 7, day_offset + 1).date()
                                        
                                        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨è¨˜éŒ„
                                        existing_schedule = Schedule.query.filter_by(
                                            date=schedule_date,
                                            employee=employee
                                        ).first()
                                        
                                        if not existing_schedule:
                                            schedule = Schedule(
                                                date=schedule_date,
                                                employee=employee,
                                                shift_type=shift_type
                                            )
                                            db.session.add(schedule)
                                            processed_count += 1
                                            print(f'è™•ç†: {employee_name} - {schedule_date} - {shift_code}')
                    
                except Exception as row_error:
                    error_count += 1
                    print(f'ç¬¬ {index+1} è¡Œè™•ç†éŒ¯èª¤: {row_error}')
                    continue
            
            db.session.commit()
            success_message = f'åŒ¯å…¥å®Œæˆï¼è™•ç†äº† {processed_count} ç­†è¨˜éŒ„ï¼Œ{error_count} ç­†éŒ¯èª¤'
            print(success_message)
            return render_template('upload.html', success=success_message)
            
        except Exception as e:
            db.session.rollback()
            error_message = f'åŒ¯å…¥å¤±æ•—: {str(e)}'
            print(error_message)
            return render_template('upload.html', error=error_message)
    
    return render_template('upload.html')

def get_shift_info(shift_code):
    """æ ¹æ“šç­åˆ¥ä»£ç¢¼è¿”å›ç­åˆ¥è³‡è¨Š"""
    from datetime import time
    
    # ä¼‘å‡ç›¸é—œ
    if shift_code in ['H0', 'H1', 'H2']:
        return f'ä¼‘å‡({shift_code})', time(0, 0), time(0, 0), '#6c757d'
    
    # æ­£å¸¸ç­åˆ¥
    elif shift_code == 'FC':
        return 'FCç­', time(9, 0), time(18, 0), '#007bff'
    
    # Pç­ç³»åˆ—
    elif shift_code.startswith('P1'):
        return f'P1ç­({shift_code})', time(8, 0), time(17, 0), '#28a745'
    elif shift_code.startswith('P2'):
        return f'P2ç­({shift_code})', time(14, 0), time(23, 0), '#ffc107'
    elif shift_code.startswith('P3'):
        return f'P3ç­({shift_code})', time(17, 0), time(2, 0), '#fd7e14'
    elif shift_code.startswith('P4'):
        return f'P4ç­({shift_code})', time(20, 0), time(5, 0), '#dc3545'
    elif shift_code.startswith('P5'):
        return f'P5ç­({shift_code})', time(22, 0), time(7, 0), '#6f42c1'
    
    # å…¶ä»–ç­åˆ¥
    elif shift_code.startswith('N'):
        return f'Nç­({shift_code})', time(19, 0), time(4, 0), '#20c997'
    elif shift_code.startswith('E'):
        return f'Eç­({shift_code})', time(7, 0), time(16, 0), '#17a2b8'
    elif shift_code.startswith('C'):
        return f'Cç­({shift_code})', time(16, 0), time(1, 0), '#e83e8c'
    elif shift_code.startswith('R'):
        return f'Rç­({shift_code})', time(12, 0), time(21, 0), '#6610f2'
    elif shift_code in ['NT', 'CH']:
        return f'{shift_code}ç­', time(9, 0), time(18, 0), '#343a40'
    elif shift_code == 'FX':
        return 'FXç­', time(10, 0), time(19, 0), '#495057'
    
    # å…¶ä»–ç‰¹æ®Šç­åˆ¥
    else:
        return f'{shift_code}ç­', time(9, 0), time(18, 0), '#868e96'

@main.route('/employee/<int:employee_id>/schedule')
def employee_schedule(employee_id):
    employee = Employee.query.get_or_404(employee_id)
    schedules = Schedule.query.filter_by(employee_id=employee_id).order_by(Schedule.date.desc()).all()
    today = date.today()
    
    return render_template('employee_schedule.html', employee=employee, schedules=schedules, today=today)

# ===== ç®¡ç†å“¡åŠŸèƒ½ =====

@main.route('/api/admin/pending-users')
@require_admin
def get_pending_users():
    """ç²å–å¾…å¯©æ ¸ç”¨æˆ¶åˆ—è¡¨"""
    try:
        pending_users = User.query.filter_by(status='pending').order_by(User.created_at.desc()).all()
        
        result = []
        for user in pending_users:
            result.append({
                'id': user.id,
                'username': user.username,
                'name': user.name,
                'status': user.status,
                'created_at': user.created_at.isoformat()
            })
        
        return jsonify({
            'success': True,
            'data': result
        })
        
    except Exception as e:
        print(f'ç²å–å¾…å¯©æ ¸ç”¨æˆ¶éŒ¯èª¤: {e}')
        return jsonify({'success': False, 'message': 'ç²å–ç”¨æˆ¶åˆ—è¡¨å¤±æ•—'}), 500

@main.route('/api/admin/approve-user', methods=['POST'])
@require_admin
def approve_user():
    """å¯©æ ¸ç”¨æˆ¶"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'success': False, 'message': 'è«‹æä¾›å¯©æ ¸è³‡æ–™'}), 400
        
        # æ”¯æ´å…©ç¨®åƒæ•¸æ ¼å¼ï¼šuserId å’Œ user_id
        user_id = data.get('userId') or data.get('user_id')
        action = data.get('action')  # 'approve' or 'reject'
        
        # ç¢ºä¿user_idæ˜¯æ•´æ•¸é¡å‹
        try:
            if user_id:
                user_id = int(user_id)
        except (ValueError, TypeError):
            return jsonify({
                'success': False, 
                'message': f'ç”¨æˆ¶IDå¿…é ˆæ˜¯æ•¸å­—ï¼Œæ”¶åˆ°: {user_id}'
            }), 400
        
        if not user_id or action not in ['approve', 'reject']:
            return jsonify({
                'success': False, 
                'message': f'ç„¡æ•ˆçš„å¯©æ ¸åƒæ•¸ - user_id: {user_id}, action: {action}'
            }), 400
        
        user = User.query.get(user_id)
        if not user:
            # å¢åŠ è¨ºæ–·ä¿¡æ¯ï¼šæŸ¥çœ‹æ‰€æœ‰ç”¨æˆ¶
            all_users = User.query.all()
            print(f'ğŸ” æ‰¾ä¸åˆ°ç”¨æˆ¶ID {user_id}ï¼Œç¾æœ‰ç”¨æˆ¶:')
            for u in all_users:
                print(f'   ID: {u.id}, ç”¨æˆ¶å: {u.username}, ç‹€æ…‹: {u.status}')
            return jsonify({'success': False, 'message': f'ç”¨æˆ¶ä¸å­˜åœ¨ (ID: {user_id})'}), 404
        
        if user.status != 'pending':
            return jsonify({'success': False, 'message': 'ç”¨æˆ¶ç‹€æ…‹ä¸æ˜¯å¾…å¯©æ ¸'}), 400
        
        # æ›´æ–°ç”¨æˆ¶ç‹€æ…‹
        if action == 'approve':
            user.status = 'approved'
            message = f'ç”¨æˆ¶ {user.name} å·²å¯©æ ¸é€šé'
        else:
            user.status = 'rejected'
            message = f'ç”¨æˆ¶ {user.name} å·²è¢«æ‹’çµ•'
        
        user.updated_at = datetime.utcnow()
        db.session.commit()
        
        return jsonify({
            'success': True,
            'message': message
        })
        
    except Exception as e:
        db.session.rollback()
        print(f'å¯©æ ¸ç”¨æˆ¶éŒ¯èª¤: {e}')
        return jsonify({'success': False, 'message': 'å¯©æ ¸å¤±æ•—'}), 500

@main.route('/api/admin/users')
@require_admin
def get_all_users():
    """ç²å–æ‰€æœ‰ç”¨æˆ¶åˆ—è¡¨"""
    try:
        users = User.query.order_by(User.created_at.desc()).all()
        
        result = []
        for user in users:
            result.append({
                'id': user.id,
                'username': user.username,
                'name': user.name,
                'role': user.role,
                'status': user.status,
                'failed_attempts': user.failed_attempts,
                'is_locked': user.is_locked(),
                'created_at': user.created_at.isoformat(),
                'updated_at': user.updated_at.isoformat() if user.updated_at else None
            })
        
        return jsonify({
            'success': True,
            'data': result
        })
        
    except Exception as e:
        print(f'ç²å–ç”¨æˆ¶åˆ—è¡¨éŒ¯èª¤: {e}')
        return jsonify({'success': False, 'message': 'ç²å–ç”¨æˆ¶åˆ—è¡¨å¤±æ•—'}), 500

@main.route('/api/admin/user/<int:user_id>/status', methods=['PUT'])
@require_admin
def update_user_status(user_id):
    """æ›´æ–°ç”¨æˆ¶ç‹€æ…‹"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'success': False, 'message': 'è«‹æä¾›ç‹€æ…‹è³‡æ–™'}), 400
        
        new_status = data.get('status')
        
        if new_status not in ['pending', 'approved', 'rejected', 'disabled']:
            return jsonify({'success': False, 'message': 'ç„¡æ•ˆçš„ç‹€æ…‹å€¼'}), 400
        
        user = User.query.get(user_id)
        if not user:
            return jsonify({'success': False, 'message': 'ç”¨æˆ¶ä¸å­˜åœ¨'}), 404
        
        # é˜²æ­¢ç®¡ç†å“¡ä¿®æ”¹è‡ªå·±çš„ç‹€æ…‹
        current_user = get_current_user()
        if user.id == current_user.id:
            return jsonify({'success': False, 'message': 'ä¸èƒ½ä¿®æ”¹è‡ªå·±çš„ç‹€æ…‹'}), 400
        
        user.status = new_status
        user.updated_at = datetime.utcnow()
        
        # å¦‚æœå•Ÿç”¨ç”¨æˆ¶ï¼Œé‡ç½®å¤±æ•—æ¬¡æ•¸
        if new_status == 'approved':
            user.reset_failed_attempts()
        
        db.session.commit()
        
        return jsonify({
            'success': True,
            'message': f'ç”¨æˆ¶ç‹€æ…‹å·²æ›´æ–°ç‚º {new_status}'
        })
        
    except Exception as e:
        db.session.rollback()
        print(f'æ›´æ–°ç”¨æˆ¶ç‹€æ…‹éŒ¯èª¤: {e}')
        return jsonify({'success': False, 'message': 'æ›´æ–°å¤±æ•—'}), 500

@main.route('/api/admin/user/<int:user_id>/unlock', methods=['POST'])
@require_admin
def unlock_user(user_id):
    """è§£é–ç”¨æˆ¶å¸³è™Ÿ"""
    try:
        user = User.query.get(user_id)
        if not user:
            return jsonify({'success': False, 'message': 'ç”¨æˆ¶ä¸å­˜åœ¨'}), 404
        
        user.reset_failed_attempts()
        user.updated_at = datetime.utcnow()
        db.session.commit()
        
        return jsonify({
            'success': True,
            'message': f'ç”¨æˆ¶ {user.name} å·²è§£é–'
        })
        
    except Exception as e:
        db.session.rollback()
        print(f'è§£é–ç”¨æˆ¶éŒ¯èª¤: {e}')
        return jsonify({'success': False, 'message': 'è§£é–å¤±æ•—'}), 500

@main.route('/admin')
@require_admin
def admin_page():
    """ç®¡ç†å“¡æ§åˆ¶å°é é¢"""
    return render_template('admin.html')

# ===== æ–°ç‰ˆExcelåŒ¯å…¥é©—è­‰ç³»çµ± v1.0 =====

@main.route('/upload_new', methods=['GET', 'POST'])
@require_admin
def upload_new():
    """æ–°ç‰ˆExcelåŒ¯å…¥é©—è­‰ç³»çµ±"""
    if request.method == 'POST':
        return handle_excel_upload()
    
    # GETè«‹æ±‚ï¼šé¡¯ç¤ºåŒ¯å…¥é é¢
    recent_imports = ImportLog.query.order_by(ImportLog.import_time.desc()).limit(5).all()
    return render_template('upload_new.html', recent_imports=recent_imports)

def handle_excel_upload():
    """è™•ç†Excelæª”æ¡ˆä¸Šå‚³å’Œé©—è­‰"""
    try:
        # 1. æª”æ¡ˆé©—è­‰
        if 'file' not in request.files:
            flash('è«‹é¸æ“‡æª”æ¡ˆ', 'error')
            return redirect(url_for('main.upload_new'))
        
        file = request.files['file']
        target_group = request.form.get('target_group')
        skip_invalid = request.form.get('skip_invalid') == 'on'
        
        if file.filename == '':
            flash('è«‹é¸æ“‡æª”æ¡ˆ', 'error')
            return redirect(url_for('main.upload_new'))
        
        if not target_group:
            flash('è«‹é¸æ“‡äººå“¡ç¾¤çµ„', 'error')
            return redirect(url_for('main.upload_new'))
        
        # è‡ªå‹•å¾æª”æ¡ˆåç¨±åˆ¤æ–·è³‡æ–™ç‰ˆæœ¬
        data_version = auto_detect_version(file.filename)
        
        if not file.filename.endswith('.csv'):
            flash('åªæ”¯æ´ CSV æ ¼å¼æª”æ¡ˆ', 'error')
            return redirect(url_for('main.upload_new'))
        
        # 2. è®€å–ç™½åå–®é…ç½®
        whitelist_data = load_whitelist()
        if not whitelist_data:
            flash('ç„¡æ³•è¼‰å…¥ç™½åå–®é…ç½®', 'error')
            return redirect(url_for('main.upload_new'))
        
        # 3. è®€å–å’Œè§£æExcel
        df = read_excel_file(file)
        if df is None:
            flash('ç„¡æ³•è®€å–Excelæª”æ¡ˆï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼', 'error')
            return redirect(url_for('main.upload_new'))
        
        # 4. è³‡æ–™é è¦½ï¼ˆå‰50ç­†ï¼‰
        preview_data = create_preview_data_v11(df, target_group, whitelist_data)
        
        # 5. è³‡æ–™é©—è­‰
        validation_result = validate_excel_data_v11(df, data_version, file.filename, target_group, whitelist_data)
        
        # 6. ç‚ºæ–°çš„åŒ¯å…¥æ–¹å¼æº–å‚™base64ç·¨ç¢¼çš„CSVè³‡æ–™
        import base64
        csv_string = df.to_csv(index=False)
        csv_base64 = base64.b64encode(csv_string.encode('utf-8')).decode('utf-8')
        validation_result['csv_data'] = csv_base64
        validation_result['target_group'] = target_group
        validation_result['filename'] = file.filename
        
        # 7. é¡¯ç¤ºçµæœé é¢
        recent_imports = ImportLog.query.order_by(ImportLog.import_time.desc()).limit(5).all()
        
        return render_template('upload_new.html', 
                             preview_data=preview_data,
                             validation_result=validation_result,
                             recent_imports=recent_imports)
        
    except Exception as e:
        flash(f'è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}', 'error')
        return redirect(url_for('main.upload_new'))

def read_excel_file(file):
    """è®€å–CSVæª”æ¡ˆä¸¦è¿”å›DataFrame"""
    return read_csv_file(file)

def read_csv_file(file):
    """è®€å–CSVæª”æ¡ˆä¸¦è¿”å›DataFrame"""
    try:
        # å˜—è©¦ä¸åŒçš„ç·¨ç¢¼
        encodings = ['utf-8', 'utf-8-sig', 'big5', 'gbk', 'cp950']
        
        for encoding in encodings:
            try:
                # é‡ç½®æª”æ¡ˆæŒ‡é‡
                file.seek(0)
                
                # å˜—è©¦è®€å–CSV
                df = pd.read_csv(file, encoding=encoding)
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«å¿…è¦æ¬„ä½
                columns_str = '|'.join(str(col).lower() for col in df.columns)
                if any(keyword in columns_str for keyword in ['å§“å', 'å“¡å·¥', 'æ—¥æœŸ', 'ç­']):
                    print(f'âœ… CSVæª”æ¡ˆä½¿ç”¨ {encoding} ç·¨ç¢¼è®€å–æˆåŠŸ')
                    return df
                    
                # å¦‚æœç¬¬ä¸€è¡Œä¸æ˜¯æ¨™é¡Œï¼Œå˜—è©¦è·³éå‰å¹¾è¡Œ
                for skip_rows in [1, 2, 3, 4]:
                    try:
                        file.seek(0)
                        df_skip = pd.read_csv(file, encoding=encoding, skiprows=skip_rows)
                        columns_str = '|'.join(str(col).lower() for col in df_skip.columns)
                        if any(keyword in columns_str for keyword in ['å§“å', 'å“¡å·¥', 'æ—¥æœŸ', 'ç­']):
                            print(f'âœ… CSVæª”æ¡ˆä½¿ç”¨ {encoding} ç·¨ç¢¼ï¼Œè·³é {skip_rows} è¡Œè®€å–æˆåŠŸ')
                            return df_skip
                    except:
                        continue
                
            except UnicodeDecodeError:
                continue
            except Exception as e:
                print(f'ä½¿ç”¨ {encoding} ç·¨ç¢¼è®€å–CSVå¤±æ•—: {e}')
                continue
        
        # å¦‚æœæ‰€æœ‰ç·¨ç¢¼éƒ½å¤±æ•—ï¼Œä½¿ç”¨é è¨­UTF-8
        file.seek(0)
        df = pd.read_csv(file, encoding='utf-8')
        print('âš ï¸ ä½¿ç”¨é è¨­UTF-8ç·¨ç¢¼è®€å–CSV')
        return df
        
    except Exception as e:
        print(f'è®€å–CSVæª”æ¡ˆéŒ¯èª¤: {e}')
        return None


def create_preview_data(df):
    """å‰µå»ºè³‡æ–™é è¦½ï¼ˆå‰10ç­†ï¼‰"""
    preview_data = []
    
    # å˜—è©¦è­˜åˆ¥æ¬„ä½
    name_col, date_col, shift_col = identify_columns(df)
    
    if not all([name_col, date_col, shift_col]):
        # å¦‚æœç„¡æ³•è­˜åˆ¥æ¬„ä½ï¼Œé¡¯ç¤ºåŸå§‹è³‡æ–™
        for i in range(min(10, len(df))):
            row = df.iloc[i]
            preview_data.append({
                'å§“å': str(row.iloc[0]) if len(row) > 0 else '',
                'æ—¥æœŸ': str(row.iloc[1]) if len(row) > 1 else '',
                'ç­åˆ¥': str(row.iloc[2]) if len(row) > 2 else ''
            })
    else:
        # ä½¿ç”¨è­˜åˆ¥çš„æ¬„ä½
        for i in range(min(10, len(df))):
            row = df.iloc[i]
            preview_data.append({
                'å§“å': str(row[name_col]) if pd.notna(row[name_col]) else '',
                'æ—¥æœŸ': str(row[date_col]) if pd.notna(row[date_col]) else '',
                'ç­åˆ¥': str(row[shift_col]) if pd.notna(row[shift_col]) else ''
            })
    
    return preview_data

def identify_columns(df):
    """è­˜åˆ¥CSVä¸­çš„å§“åã€æ—¥æœŸã€ç­åˆ¥æ¬„ä½ - å„ªåŒ–ç›´å¼æ ¼å¼æ”¯æ´"""
    name_col = None
    date_col = None
    shift_col = None
    
    # èª¿è©¦è¼¸å‡º
    print(f"CSVæ¬„ä½: {list(df.columns)}")
    print(f"ç¬¬ä¸€è¡Œè³‡æ–™: {list(df.iloc[0]) if len(df) > 0 else 'N/A'}")
    
    # å„ªå…ˆè™•ç†ç›´å¼æ ¼å¼ - æª¢æŸ¥column headers
    for col in df.columns:
        col_str = str(col).lower().strip()
        print(f"æª¢æŸ¥æ¬„ä½: '{col}' -> '{col_str}'")
        
        # å§“åæ¬„ä½è­˜åˆ¥
        if col_str in ['å§“å', 'å“¡å·¥å§“å', 'name', 'åå­—'] and not name_col:
            name_col = col
            print(f"æ‰¾åˆ°å§“åæ¬„ä½: {col}")
        
        # æ—¥æœŸæ¬„ä½è­˜åˆ¥
        elif col_str in ['æ—¥æœŸ', 'date', 'æ™‚é–“', 'datetime'] and not date_col:
            date_col = col
            print(f"æ‰¾åˆ°æ—¥æœŸæ¬„ä½: {col}")
        
        # ç­åˆ¥æ¬„ä½è­˜åˆ¥
        elif col_str in ['ç­åˆ¥', 'ç­æ¬¡', 'shift', 'æ’ç­'] and not shift_col:
            shift_col = col
            print(f"æ‰¾åˆ°ç­åˆ¥æ¬„ä½: {col}")
    
    # å¦‚æœç›´å¼æ ¼å¼è­˜åˆ¥å¤±æ•—ï¼Œå˜—è©¦æ©«å¼æ ¼å¼ï¼ˆæ•¸å­—æ¬„ä½ï¼‰
    if not date_col:
        numeric_cols = [col for col in df.columns if str(col).strip().isdigit()]
        if numeric_cols:
            date_col = numeric_cols[0]  # å–ç¬¬ä¸€å€‹æ•¸å­—æ¬„ä½ä½œç‚ºæ—¥æœŸ
            print(f"ä½¿ç”¨æ•¸å­—æ¬„ä½ä½œç‚ºæ—¥æœŸï¼ˆæ©«å¼æ ¼å¼ï¼‰: {date_col}")
    
    # å¦‚æœä»æœªæ‰¾åˆ°å¿…è¦æ¬„ä½ï¼Œæª¢æŸ¥ç¬¬ä¸€è¡Œè³‡æ–™æ˜¯å¦ç‚ºæ¬„ä½åç¨±
    if not all([name_col, date_col, shift_col]) and len(df) > 0:
        first_row = df.iloc[0]
        print(f"æª¢æŸ¥ç¬¬ä¸€è¡Œä½œç‚ºæ¬„ä½åç¨±: {list(first_row)}")
        
        for idx, cell in enumerate(first_row):
            cell_str = str(cell).strip()
            if cell_str == 'å§“å' and not name_col:
                name_col = df.columns[idx]
                print(f"åœ¨ç¬¬ä¸€è¡Œæ‰¾åˆ°å§“åæ¬„ä½ï¼Œå°æ‡‰æ¬„ä½: {name_col}")
    
    print(f"è­˜åˆ¥çµæœ: å§“å={name_col}, æ—¥æœŸ={date_col}, ç­åˆ¥={shift_col}")
    if date_col and str(date_col).strip().isdigit():
        print(f"æ•¸å­—æ¬„ä½: {[col for col in df.columns if str(col).strip().isdigit()][:10]}...")
    
    return name_col, date_col, shift_col

def validate_excel_data(df, data_version, filename):
    """é©—è­‰Excelè³‡æ–™"""
    result = {
        'status': 'OK',
        'total_records': len(df),
        'valid_records': 0,
        'warnings': 0,
        'errors': 0,
        'error_messages': [],
        'filename': filename,
        'data_version': data_version
    }
    
    try:
        # 1. æ¬„ä½é©—è­‰
        name_col, date_col, shift_col = identify_columns(df)
        
        if not name_col:
            result['errors'] += 1
            result['error_messages'].append('æ‰¾ä¸åˆ°å§“åæ¬„ä½ï¼ˆæ‡‰åŒ…å«ï¼šå§“åã€å“¡å·¥å§“åæˆ–nameï¼‰')
            result['status'] = 'ERROR'
        
        if not date_col:
            result['errors'] += 1
            result['error_messages'].append('æ‰¾ä¸åˆ°æ—¥æœŸæ¬„ä½ï¼ˆæ‡‰åŒ…å«ï¼šæ—¥æœŸæˆ–dateï¼‰')
            result['status'] = 'ERROR'
        
        if not shift_col:
            result['errors'] += 1
            result['error_messages'].append('æ‰¾ä¸åˆ°ç­åˆ¥æ¬„ä½ï¼ˆæ‡‰åŒ…å«ï¼šç­åˆ¥ã€ç­æ¬¡æˆ–shiftï¼‰')
            result['status'] = 'ERROR'
        
        # å¦‚æœåŸºæœ¬æ¬„ä½éƒ½æ‰¾ä¸åˆ°ï¼Œç›´æ¥è¿”å›
        if result['status'] == 'ERROR':
            return result
        
        # 2. è³‡æ–™å…§å®¹é©—è­‰
        valid_shifts = get_valid_shift_codes()
        target_employees = get_target_employees()
        
        for index, row in df.iterrows():
            try:
                # å§“åé©—è­‰
                employee_name = str(row[name_col]).strip() if pd.notna(row[name_col]) else ''
                if not employee_name:
                    result['errors'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šå§“åæ¬„ä½ç©ºç™½')
                    continue
                
                # ç¾¤çµ„éæ¿¾ï¼šåªè™•ç†å±¬æ–¼ç›®æ¨™ç¾¤çµ„çš„å“¡å·¥ï¼Œè·³éå…¶ä»–å“¡å·¥
                if employee_name not in target_employees:
                    # è·³éä¸åœ¨ç›®æ¨™ç¾¤çµ„ä¸­çš„å“¡å·¥ï¼Œä¸é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
                    continue
                
                # æ—¥æœŸé©—è­‰
                date_value = row[date_col] if pd.notna(row[date_col]) else None
                if not date_value:
                    result['errors'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šæ—¥æœŸæ¬„ä½ç©ºç™½')
                    continue
                
                # ç­åˆ¥é©—è­‰
                shift_code = str(row[shift_col]).strip() if pd.notna(row[shift_col]) else ''
                if not shift_code:
                    result['errors'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šç­åˆ¥æ¬„ä½ç©ºç™½')
                    continue
                
                if shift_code not in valid_shifts:
                    result['warnings'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šæœªçŸ¥ç­åˆ¥ä»£ç¢¼ {shift_code}')
                    if result['status'] == 'OK':
                        result['status'] = 'WARNING'
                
                result['valid_records'] += 1
                
            except Exception as e:
                result['errors'] += 1
                result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šè³‡æ–™è™•ç†éŒ¯èª¤ - {str(e)}')
        
        # 3. è¨­å®šæœ€çµ‚ç‹€æ…‹
        if result['errors'] > 0:
            result['status'] = 'ERROR'
        elif result['warnings'] > 0:
            result['status'] = 'WARNING'
        
        return result
        
    except Exception as e:
        result['status'] = 'ERROR'
        result['errors'] += 1
        result['error_messages'].append(f'é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
        return result

def get_valid_shift_codes():
    """ç²å–æœ‰æ•ˆç­åˆ¥ä»£ç¢¼ - å¾è³‡æ–™åº«å‹•æ…‹è¼‰å…¥"""
    try:
        from app.models import ShiftType
        shift_codes = [shift.code for shift in ShiftType.query.all()]
        print(f"âœ… å¾è³‡æ–™åº«è¼‰å…¥ {len(shift_codes)} å€‹ç­åˆ¥ä»£ç¢¼: {shift_codes}")
        return shift_codes
    except Exception as e:
        print(f"âš ï¸ è¼‰å…¥ç­åˆ¥ä»£ç¢¼å¤±æ•—ï¼Œä½¿ç”¨é è¨­æ¸…å–®: {e}")
        # é è¨­æ¸…å–®ä½œç‚ºå‚™ç”¨ï¼ˆåŒ…å«æ‰€æœ‰æˆ‘å€‘å·²åˆå§‹åŒ–çš„ç­åˆ¥ï¼‰
        return [
            'A', 'B', 'C', 'OFF', 'FC', 'FC/å·¥ç¨‹', 'FC/æ€¥æ•‘èª²', 'FX',
            'P1s', 'P1s2', 'P1c', 'P1c2', 'P1n', 'P1n/å¤œè¶…', 'P1p', 'P1p2', 'P1p/ME',
            'P2s', 'P2c', 'P2n', 'P2p', 'P2p/LD',
            'P3c', 'P3n', 'P3n/å¤œè¶…', 'P3p',
            'P4c', 'P4n', 'P4p',
            'P5', 'P6', 'C1', 'C3', 'N1', 'N2', 'E1', 'R1',
            'H0', 'H1', 'èˆå°'
        ]

def load_whitelist():
    """è¼‰å…¥ç™½åå–®é…ç½®"""
    try:
        whitelist_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'whitelist.json')
        with open(whitelist_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f'è¼‰å…¥ç™½åå–®é…ç½®éŒ¯èª¤: {e}')
        return None

def auto_detect_version(filename):
    """æ ¹æ“šæª”æ¡ˆåç¨±è‡ªå‹•æª¢æ¸¬è³‡æ–™ç‰ˆæœ¬ - çµ±ä¸€ä½¿ç”¨ä¸€èˆ¬ç‰ˆæœ¬"""
    return 'ä¸€èˆ¬ç‰ˆæœ¬'

def create_preview_data_v11(df, target_group, whitelist_data):
    """å‰µå»ºv1.2ç‰ˆæœ¬çš„è³‡æ–™é è¦½ - å„ªåŒ–ç›´å¼æ ¼å¼æ”¯æ´"""
    preview_data = []
    
    # ç‡ˆå…‰çµ„æ ¸å¿ƒ7äººåå–®
    core_light_crew = ['è³´ ç§‰ å®', 'æ æƒŸ ç¶±', 'æ å®¶ ç‘‹', 'ç‹ å¿— å¿ ', 'é¡§ è‚² ç¦', 'èƒ¡ ç¿Š æ½”', 'æœ± å®¶ å¾·']
    
    # å˜—è©¦è­˜åˆ¥æ¬„ä½
    name_col, date_col, shift_col = identify_columns(df)
    valid_shifts = get_valid_shift_codes()
    
    # å„ªå…ˆè™•ç†ç›´å¼æ ¼å¼ï¼ˆæ¨™æº–CSVæ ¼å¼ï¼‰
    if name_col and date_col and shift_col:
        # ç²å–ç›®æ¨™ç¾¤çµ„çš„å“¡å·¥åå–®
        if target_group == 'å…¨åå–®':
            valid_names = whitelist_data.get('allowed', [])
        else:
            valid_names = whitelist_data.get('group', {}).get(target_group, [])
        
        record_count = 0
        for i in range(len(df)):
            if record_count >= 50:  # é™åˆ¶é è¦½50ç­†
                break
                
            row = df.iloc[i]
            employee_name = str(row[name_col]).strip() if pd.notna(row[name_col]) else ''
            
            # åªé¡¯ç¤ºç›®æ¨™ç¾¤çµ„çš„è¨˜éŒ„
            if employee_name not in valid_names:
                continue
            
            record_count += 1
            issues = []
            status = 'ok'
            
            # æå–ä¸¦é©—è­‰è³‡æ–™
            date_value = row[date_col] if pd.notna(row[date_col]) else None
            shift_code = str(row[shift_col]).strip() if pd.notna(row[shift_col]) else ''
            
            # æ ¼å¼åŒ–æ—¥æœŸ
            formatted_date = ''
            if date_value:
                try:
                    if isinstance(date_value, str):
                        parsed_date = datetime.strptime(date_value, '%Y-%m-%d').date()
                        formatted_date = parsed_date.strftime('%Y/%m/%d')
                    else:
                        if hasattr(date_value, 'date'):
                            formatted_date = date_value.date().strftime('%Y/%m/%d')
                        else:
                            formatted_date = date_value.strftime('%Y/%m/%d')
                except:
                    formatted_date = str(date_value)
                    issues.append('æ—¥æœŸæ ¼å¼éŒ¯èª¤')
                    status = 'error'
            else:
                issues.append('æ—¥æœŸæ¬„ä½ç©ºç™½')
                status = 'error'
            
            # é©—è­‰å§“å
            if not employee_name:
                issues.append('å§“åæ¬„ä½ç©ºç™½')
                status = 'error'
            
            # é©—è­‰ç­åˆ¥
            if not shift_code:
                issues.append('ç­åˆ¥æ¬„ä½ç©ºç™½')
                status = 'error'
            elif shift_code not in valid_shifts:
                issues.append(f'ç­åˆ¥ä»£è™ŸéŒ¯èª¤ï¼š{shift_code}')
                status = 'error'
            
            preview_data.append({
                'row': i + 2,
                'name': employee_name,
                'date': formatted_date if formatted_date else str(date_value),
                'shift': shift_code,
                'status': status,
                'message': '; '.join(issues) if issues else ''
            })
        
        return preview_data
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºæ©«å¼æ ¼å¼ï¼ˆæ•¸å­—æ¬„ä½ä»£è¡¨æ—¥æœŸï¼‰
    numeric_cols = [col for col in df.columns if str(col).strip().isdigit()]
    
    if numeric_cols:
        # è™•ç†æ©«å¼æ ¼å¼
        for i in range(len(df)):
            row = df.iloc[i]
            
            # å˜—è©¦å¤šç¨®æ–¹å¼æ‰¾åˆ°å§“å
            employee_name = ''
            
            # æ–¹å¼1: ä½¿ç”¨è­˜åˆ¥åˆ°çš„å§“åæ¬„ä½
            if name_col and name_col in df.columns:
                employee_name = str(row[name_col]).strip() if pd.notna(row[name_col]) else ''
            
            # æ–¹å¼2: æª¢æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æœ‰å§“åè³‡è¨Šï¼Œå¦‚æœæœ‰ï¼Œä½¿ç”¨å°æ‡‰ä½ç½®
            if not employee_name and len(df) > 0:
                first_row = df.iloc[0]
                for col_idx, header_value in enumerate(first_row):
                    if str(header_value).strip() == 'å§“å' and col_idx < len(row):
                        employee_name = str(row.iloc[col_idx]).strip() if pd.notna(row.iloc[col_idx]) else ''
                        break
            
            # æ–¹å¼3: å˜—è©¦ç¬¬ä¸€æ¬„
            if not employee_name:
                employee_name = str(row.iloc[0]).strip() if len(row) > 0 and pd.notna(row.iloc[0]) else ''
            
            # è·³éæ¨™é¡Œè¡Œå’Œéæ ¸å¿ƒ7äººè¨˜éŒ„
            if employee_name in ['å§“å', 'å¹´æœˆ', 'çµ„å®¤åˆ¥', 'å“¡å·¥ä»£ç¢¼'] or employee_name not in core_light_crew:
                continue
            
            # éæ­·æ¯å€‹æ•¸å­—æ¬„ä½ï¼ˆæ—¥æœŸï¼‰ï¼Œåªé è¦½å‰10å¤©
            for day_col in numeric_cols[:10]:
                if day_col in row.index:
                    shift_value = str(row[day_col]).strip() if pd.notna(row[day_col]) else ''
                    
                    if shift_value and shift_value not in ['nan', '']:
                        issues = []
                        status = 'ok'
                        
                        if shift_value not in valid_shifts:
                            issues.append(f'ç­åˆ¥ä»£è™ŸéŒ¯èª¤ï¼š{shift_value}')
                            status = 'error'
                        
                        try:
                            day_num = int(day_col)
                            formatted_date = f'2025-07-{day_num:02d}'
                        except:
                            formatted_date = str(day_col)
                        
                        preview_data.append({
                            'row': i + 2,
                            'name': employee_name,
                            'date': formatted_date,
                            'shift': shift_value,
                            'status': status,
                            'message': '; '.join(issues) if issues else ''
                        })
                        
                        if len(preview_data) >= 50:  # é™åˆ¶é è¦½æ•¸é‡
                            return preview_data
    
    # å¦‚æœç„¡æ³•è­˜åˆ¥ä»»ä½•æ ¼å¼ï¼Œé¡¯ç¤ºåŸºæœ¬è³‡è¨Š
    if not preview_data:
        for i in range(min(10, len(df))):
            row = df.iloc[i]
            preview_data.append({
                'row': i + 2,
                'name': str(row.iloc[0]) if len(row) > 0 else '',
                'date': str(row.iloc[1]) if len(row) > 1 else '',
                'shift': str(row.iloc[2]) if len(row) > 2 else '',
                'status': 'warning',
                'message': 'ç„¡æ³•è­˜åˆ¥æª”æ¡ˆæ ¼å¼'
            })
    
    return preview_data

def validate_excel_data_v11(df, data_version, filename, target_group, whitelist_data):
    """v1.1ç‰ˆæœ¬çš„Excelè³‡æ–™é©—è­‰"""
    result = {
        'status': 'OK',
        'total_records': len(df),
        'valid_records': 0,
        'warnings': 0,
        'errors': 0,
        'error_messages': [],
        'filename': filename,
        'data_version': data_version,
        'target_group': target_group
    }
    
    try:
        # 1. æ¬„ä½é©—è­‰
        name_col, date_col, shift_col = identify_columns(df)
        
        if not name_col:
            result['errors'] += 1
            result['error_messages'].append('æ‰¾ä¸åˆ°å§“åæ¬„ä½ï¼ˆæ‡‰åŒ…å«ï¼šå§“åã€å“¡å·¥å§“åæˆ–nameï¼‰')
            result['status'] = 'ERROR'
        
        if not date_col:
            result['errors'] += 1
            result['error_messages'].append('æ‰¾ä¸åˆ°æ—¥æœŸæ¬„ä½ï¼ˆæ‡‰åŒ…å«ï¼šæ—¥æœŸæˆ–dateï¼‰')
            result['status'] = 'ERROR'
        
        if not shift_col:
            result['errors'] += 1
            result['error_messages'].append('æ‰¾ä¸åˆ°ç­åˆ¥æ¬„ä½ï¼ˆæ‡‰åŒ…å«ï¼šç­åˆ¥ã€ç­æ¬¡æˆ–shiftï¼‰')
            result['status'] = 'ERROR'
        
        # å¦‚æœåŸºæœ¬æ¬„ä½éƒ½æ‰¾ä¸åˆ°ï¼Œç›´æ¥è¿”å›
        if result['status'] == 'ERROR':
            return result
        
        # 2. ç²å–ç™½åå–®å’Œæœ‰æ•ˆç­åˆ¥
        if target_group == 'å…¨åå–®':
            valid_names = whitelist_data.get('allowed', [])
        else:
            valid_names = whitelist_data.get('group', {}).get(target_group, [])
        
        valid_shifts = get_valid_shift_codes()
        
        # 3. è³‡æ–™å…§å®¹é©—è­‰
        daily_schedules = {}  # ç”¨æ–¼æª¢æŸ¥é‡è¤‡å’Œå–®æ—¥äººæ•¸
        
        for index, row in df.iterrows():
            try:
                # å§“åé©—è­‰
                employee_name = str(row[name_col]).strip() if pd.notna(row[name_col]) else ''
                if not employee_name:
                    result['errors'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šå§“åæ¬„ä½ç©ºç™½')
                    continue
                
                # ç¾¤çµ„éæ¿¾ï¼šåªè™•ç†å±¬æ–¼ç›®æ¨™ç¾¤çµ„çš„å“¡å·¥ï¼Œè·³éå…¶ä»–å“¡å·¥
                if employee_name not in valid_names:
                    # è·³éä¸åœ¨ç›®æ¨™ç¾¤çµ„ä¸­çš„å“¡å·¥ï¼Œä¸é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
                    continue
                
                # æ—¥æœŸé©—è­‰
                date_value = row[date_col] if pd.notna(row[date_col]) else None
                if not date_value:
                    result['errors'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šæ—¥æœŸæ¬„ä½ç©ºç™½')
                    continue
                
                # å˜—è©¦è§£ææ—¥æœŸ
                try:
                    if isinstance(date_value, str):
                        schedule_date = datetime.strptime(date_value, '%Y-%m-%d').date()
                    else:
                        schedule_date = date_value.date() if hasattr(date_value, 'date') else date_value
                except:
                    result['errors'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šæ—¥æœŸæ¬„éæ—¥æœŸæ ¼å¼')
                    continue
                
                # ç­åˆ¥é©—è­‰
                shift_code = str(row[shift_col]).strip() if pd.notna(row[shift_col]) else ''
                if not shift_code:
                    result['errors'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šç­åˆ¥æ¬„ä½ç©ºç™½')
                    continue
                
                if shift_code not in valid_shifts:
                    result['errors'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šç­åˆ¥ä»£è™ŸéŒ¯èª¤ï¼š{shift_code}')
                    continue
                
                # é‡è¤‡è³‡æ–™æª¢æŸ¥
                schedule_key = f"{employee_name}_{schedule_date}"
                if schedule_key in daily_schedules:
                    result['warnings'] += 1
                    result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šé‡è¤‡è³‡æ–™ - {employee_name} åœ¨ {schedule_date} å·²æœ‰æ’ç­')
                    if result['status'] == 'OK':
                        result['status'] = 'WARNING'
                else:
                    daily_schedules[schedule_key] = True
                    
                    # çµ±è¨ˆæ¯æ—¥äººæ•¸
                    if schedule_date not in daily_schedules:
                        daily_schedules[schedule_date] = []
                    daily_schedules[schedule_date].append(employee_name)
                
                result['valid_records'] += 1
                
            except Exception as e:
                result['errors'] += 1
                result['error_messages'].append(f'ç¬¬{index+2}è¡Œï¼šè³‡æ–™è™•ç†éŒ¯èª¤ - {str(e)}')
        
        # 4. æª¢æŸ¥å–®æ—¥äººæ•¸è­¦å‘Š
        for schedule_date, employees in daily_schedules.items():
            if isinstance(employees, list) and len(employees) == 1:
                result['warnings'] += 1
                result['error_messages'].append(f'{schedule_date}ï¼šç•¶æ—¥åƒ…ä¸€äººä¸Šç­ï¼Œè«‹æ³¨æ„è£œäººæ‰‹')
                if result['status'] == 'OK':
                    result['status'] = 'WARNING'
        
        # 5. æª¢æŸ¥ç‡ˆå…‰çµ„æ ¸å¿ƒ7äººç­æ•¸å¹³è¡¡ï¼ˆæ”¯æ´ç›´å¼å’Œæ©«å¼æ ¼å¼ï¼‰
        core_light_crew = ['è³´ ç§‰ å®', 'æ æƒŸ ç¶±', 'æ å®¶ ç‘‹', 'ç‹ å¿— å¿ ', 'é¡§ è‚² ç¦', 'èƒ¡ ç¿Š æ½”', 'æœ± å®¶ å¾·']
        core_crew_stats = {}
        
        # åˆ¤æ–·æ˜¯ç›´å¼é‚„æ˜¯æ©«å¼æ ¼å¼
        is_vertical_format = (name_col and shift_col and 
                             'å§“å' in str(name_col).lower() and 
                             ('ç­åˆ¥' in str(shift_col).lower() or 'shift' in str(shift_col).lower()))
        
        if is_vertical_format:
            # ç›´å¼æ ¼å¼çµ±è¨ˆï¼šæ¯è¡Œä»£è¡¨ä¸€å€‹äººä¸€å¤©çš„ç­åˆ¥
            for index, row in df.iterrows():
                try:
                    # ç²å–å§“å
                    employee_name = str(row[name_col]).strip() if pd.notna(row[name_col]) else ''
                    
                    # è·³éæ¨™é¡Œè¡Œ
                    if employee_name in ['å§“å', 'å¹´æœˆ', 'çµ„å®¤åˆ¥', 'å“¡å·¥ä»£ç¢¼']:
                        continue
                    
                    if employee_name in core_light_crew:
                        if employee_name not in core_crew_stats:
                            core_crew_stats[employee_name] = 0
                        
                        # ç²å–ç­åˆ¥
                        shift_value = str(row[shift_col]).strip() if pd.notna(row[shift_col]) else ''
                        
                        # è¨ˆç®—ç­æ•¸ï¼šæ’é™¤ä¼‘å‡ã€èˆå°ç­å’Œç©ºå€¼
                        if shift_value and shift_value not in ['OFF', 'nan', '', 'ä¼‘å‡', 'èˆå°']:
                            core_crew_stats[employee_name] += 1
                            
                except Exception as e:
                    print(f"çµ±è¨ˆæ ¸å¿ƒäººå“¡æ™‚å‡ºéŒ¯ (ç›´å¼): {e}")
                    continue
        else:
            # æ©«å¼æ ¼å¼çµ±è¨ˆï¼šå‚³çµ±æ–¹å¼
            numeric_cols = [col for col in df.columns if str(col).strip().isdigit()]
            
            for index, row in df.iterrows():
                try:
                    # å˜—è©¦å¤šç¨®æ–¹å¼æ‰¾åˆ°å§“å
                    employee_name = ''
                    
                    # æ–¹å¼1: ä½¿ç”¨è­˜åˆ¥åˆ°çš„å§“åæ¬„ä½
                    if name_col and name_col in df.columns:
                        employee_name = str(row[name_col]).strip() if pd.notna(row[name_col]) else ''
                    
                    # æ–¹å¼2: æª¢æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æœ‰å§“åè³‡è¨Š
                    if not employee_name and len(df) > 0:
                        first_row = df.iloc[0]
                        for col_idx, header_value in enumerate(first_row):
                            if str(header_value).strip() == 'å§“å' and col_idx < len(row):
                                employee_name = str(row.iloc[col_idx]).strip() if pd.notna(row.iloc[col_idx]) else ''
                                break
                    
                    # æ–¹å¼3: å˜—è©¦ç¬¬ä¸€æ¬„
                    if not employee_name:
                        employee_name = str(row.iloc[0]).strip() if len(row) > 0 and pd.notna(row.iloc[0]) else ''
                    
                    # è·³éæ¨™é¡Œè¡Œ
                    if employee_name in ['å§“å', 'å¹´æœˆ', 'çµ„å®¤åˆ¥', 'å“¡å·¥ä»£ç¢¼']:
                        continue
                    
                    if employee_name in core_light_crew:
                        if employee_name not in core_crew_stats:
                            core_crew_stats[employee_name] = 0
                        
                        # çµ±è¨ˆè©²å“¡å·¥åœ¨æ‰€æœ‰æ—¥æœŸæ¬„ä½ä¸­çš„ç­åˆ¥æ•¸
                        for day_col in numeric_cols:
                            if day_col in row.index:
                                shift_value = str(row[day_col]).strip() if pd.notna(row[day_col]) else ''
                                if shift_value and shift_value not in ['OFF', 'nan', '', 'ä¼‘å‡', 'èˆå°']:
                                    core_crew_stats[employee_name] += 1
                        
                except Exception as e:
                    print(f"çµ±è¨ˆæ ¸å¿ƒäººå“¡æ™‚å‡ºéŒ¯ (æ©«å¼): {e}")
                    continue
        
        # å°‡çµ±è¨ˆçµæœåŠ å…¥é©—è­‰çµæœ
        result['core_light_crew_stats'] = core_crew_stats
        
        # æª¢æŸ¥ç­æ•¸æ˜¯å¦å¹³è¡¡
        if core_crew_stats:
            shift_counts = list(core_crew_stats.values())
            if shift_counts and len(set(shift_counts)) > 1:
                min_count = min(shift_counts)
                max_count = max(shift_counts)
                result['warnings'] += 1
                result['error_messages'].append(f'ç‡ˆå…‰çµ„æ ¸å¿ƒäººå“¡ç­æ•¸ä¸å¹³è¡¡ï¼šæœ€å°‘{min_count}ç­ï¼Œæœ€å¤š{max_count}ç­')
                if result['status'] == 'OK':
                    result['status'] = 'WARNING'
                
                # è©³ç´°åˆ—å‡ºæ¯å€‹äººçš„ç­æ•¸
                stats_details = []
                for name, count in core_crew_stats.items():
                    stats_details.append(f'{name}: {count}ç­')
                result['error_messages'].append(f'æ ¸å¿ƒäººå“¡ç­æ•¸æ˜ç´°ï¼š{", ".join(stats_details)}')
        
        # 6. è¨­å®šæœ€çµ‚ç‹€æ…‹
        if result['errors'] > 0:
            result['status'] = 'ERROR'
        elif result['warnings'] > 0:
            result['status'] = 'WARNING'
        
        return result
        
    except Exception as e:
        result['status'] = 'ERROR'
        result['errors'] += 1
        result['error_messages'].append(f'é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
        return result

def get_target_employees():
    """ç²å–ç›®æ¨™å“¡å·¥åå–®ï¼ˆä¿ç•™å‘å¾Œå…¼å®¹æ€§ï¼‰"""
    return [
        'è³´ç§‰å®', 'ææƒŸç¶±', 'æå®¶ç‘‹', 'ç‹å¿—å¿ ', 'é¡§è‚²ç¦',
        'èƒ¡ç¿Šæ½”', 'æœ±å®¶å¾·', 'é™³éŸ‹å¦‚', 'è‘›ç¦', 'äº•åº·ç¾½',
        'ç°¡èŠ³ç‘œ', 'æ¢å¼˜å²³', 'æä½©ç’‡', 'é„­æ ¢ç”', 'ç‹æ–‡æ€¡'
    ]

@main.route('/confirm_import', methods=['POST'])
@require_admin
def confirm_import():
    """ç¢ºèªä¸¦åŸ·è¡ŒåŒ¯å…¥ï¼ˆç„¡éœ€sessionæš«å­˜ï¼‰"""
    try:
        csv_data = request.form.get('csv_data')
        target_group = request.form.get('target_group')
        filename = request.form.get('filename')
        force_import = request.form.get('force_import') == 'true'
        
        if not csv_data or not target_group or not filename:
            flash('åŒ¯å…¥è³‡æ–™ä¸å®Œæ•´ï¼Œè«‹é‡æ–°ä¸Šå‚³', 'error')
            return redirect(url_for('main.upload_new'))
        
        # è§£æCSVè³‡æ–™
        import io
        import base64
        csv_string = base64.b64decode(csv_data).decode('utf-8')
        df = pd.read_csv(io.StringIO(csv_string))
        
        # é‡æ–°é©—è­‰è³‡æ–™
        whitelist_data = load_whitelist()
        validation_result = validate_excel_data_v11(df, 'ä¸€èˆ¬ç‰ˆæœ¬', filename, target_group, whitelist_data)
        
        # æª¢æŸ¥æ˜¯å¦å¯ä»¥åŒ¯å…¥
        if validation_result['status'] == 'ERROR' and not force_import:
            flash('è³‡æ–™æœ‰éŒ¯èª¤ï¼Œç„¡æ³•åŒ¯å…¥', 'error')
            return redirect(url_for('main.upload_new'))
        
        # åŸ·è¡ŒåŒ¯å…¥
        import_result = perform_data_import_v11(df, validation_result, target_group, False)
        
        # è¨˜éŒ„åŒ¯å…¥æ—¥èªŒ
        current_user = get_current_user()
        import_log = ImportLog(
            importer=current_user.name,
            filename=filename,
            data_version='ä¸€èˆ¬ç‰ˆæœ¬',
            target_group=target_group,
            validation_result=validation_result['status'],
            force_import=force_import,
            error_count=validation_result['errors'],
            warning_count=validation_result['warnings'],
            records_imported=import_result['imported_count']
        )
        
        if validation_result['error_messages']:
            import_log.set_validation_errors(validation_result['error_messages'])
        
        db.session.add(import_log)
        db.session.commit()
        
        # é¡¯ç¤ºçµæœè¨Šæ¯
        if import_result['success']:
            flash(f'âœ… åŒ¯å…¥æˆåŠŸï¼å…±è™•ç† {import_result["imported_count"]} ç­†è¨˜éŒ„', 'success')
        else:
            flash(f'âŒ åŒ¯å…¥å¤±æ•—ï¼š{import_result["error"]}', 'error')
        
        return redirect(url_for('main.upload_new'))
        
    except Exception as e:
        print(f"åŒ¯å…¥éŒ¯èª¤: {e}")
        flash(f'åŒ¯å…¥éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}', 'error')
        return redirect(url_for('main.upload_new'))

@main.route('/execute_import', methods=['POST'])
@require_admin
def execute_import():
    """åŸ·è¡ŒåŒ¯å…¥ä½œæ¥­"""
    try:
        data_hash = request.form.get('validated_data')
        force_import = request.form.get('force_import') == 'true'
        
        if not data_hash or f'validated_data_{data_hash}' not in session:
            flash('é©—è­‰è³‡æ–™å·²éæœŸï¼Œè«‹é‡æ–°ä¸Šå‚³', 'error')
            return redirect(url_for('main.upload_new'))
        
        cached_data = session[f'validated_data_{data_hash}']
        df = pd.read_json(cached_data['df'])
        validation_result = cached_data['validation_result']
        filename = cached_data['filename']
        data_version = cached_data['data_version']
        target_group = cached_data.get('target_group', 'å…¨åå–®')
        skip_invalid = cached_data.get('skip_invalid', False)
        
        # æª¢æŸ¥æ˜¯å¦å¯ä»¥åŒ¯å…¥
        if validation_result['status'] == 'ERROR' and not force_import:
            flash('è³‡æ–™æœ‰éŒ¯èª¤ï¼Œç„¡æ³•åŒ¯å…¥', 'error')
            return redirect(url_for('main.upload_new'))
        
        # åŸ·è¡ŒåŒ¯å…¥
        import_result = perform_data_import_v11(df, validation_result, target_group, skip_invalid)
        
        # è¨˜éŒ„åŒ¯å…¥æ—¥èªŒ
        current_user = get_current_user()
        import_log = ImportLog(
            importer=current_user.name,
            filename=filename,
            data_version=data_version,
            target_group=target_group,
            validation_result=validation_result['status'],
            force_import=force_import,
            error_count=validation_result['errors'],
            warning_count=validation_result['warnings'],
            records_imported=import_result['imported_count']
        )
        
        if validation_result['error_messages']:
            import_log.set_validation_errors(validation_result['error_messages'])
        
        db.session.add(import_log)
        db.session.commit()
        
        # æ¸…ç†ç·©å­˜
        del session[f'validated_data_{data_hash}']
        
        success_message = f'åŒ¯å…¥å®Œæˆï¼æˆåŠŸåŒ¯å…¥ {import_result["imported_count"]} ç­†è¨˜éŒ„'
        if import_result['skipped_count'] > 0:
            success_message += f'ï¼Œè·³é {import_result["skipped_count"]} ç­†é‡è¤‡è¨˜éŒ„'
        
        flash(success_message, 'success')
        return redirect(url_for('main.upload_new'))
        
    except Exception as e:
        db.session.rollback()
        flash(f'åŒ¯å…¥å¤±æ•—: {str(e)}', 'error')
        return redirect(url_for('main.upload_new'))

def perform_data_import_v11(df, validation_result, target_group, skip_invalid):
    """åŸ·è¡Œv1.1ç‰ˆæœ¬çš„å¯¦éš›è³‡æ–™åŒ¯å…¥"""
    imported_count = 0
    skipped_count = 0
    
    try:
        # è¼‰å…¥ç™½åå–®
        whitelist_data = load_whitelist()
        if target_group == 'å…¨åå–®':
            valid_names = whitelist_data.get('allowed', [])
        else:
            valid_names = whitelist_data.get('group', {}).get(target_group, [])
        
        valid_shifts = get_valid_shift_codes()
        name_col, date_col, shift_col = identify_columns(df)
        
        for index, row in df.iterrows():
            try:
                # æå–è³‡æ–™
                employee_name = str(row[name_col]).strip()
                date_value = row[date_col]
                shift_code = str(row[shift_col]).strip()
                
                # è·³éç©ºç™½æˆ–ç„¡æ•ˆè³‡æ–™
                if not employee_name or not shift_code or pd.isna(date_value):
                    continue
                
                # ç¾¤çµ„éæ¿¾æª¢æŸ¥ï¼šå¦‚æœä¸æ˜¯å…¨åå–®æ¨¡å¼ï¼Œåªè™•ç†ç›®æ¨™ç¾¤çµ„çš„å“¡å·¥
                if target_group != 'å…¨åå–®' and employee_name not in valid_names:
                    skipped_count += 1
                    continue
                
                # ç­åˆ¥ä»£ç¢¼æª¢æŸ¥
                if shift_code not in valid_shifts:
                    skipped_count += 1
                    continue
                
                # è™•ç†æ—¥æœŸ
                try:
                    if isinstance(date_value, str):
                        schedule_date = datetime.strptime(date_value, '%Y-%m-%d').date()
                    else:
                        schedule_date = date_value.date() if hasattr(date_value, 'date') else date_value
                except:
                    skipped_count += 1
                    continue
                
                # æŸ¥æ‰¾æˆ–å‰µå»ºå“¡å·¥
                employee = Employee.query.filter_by(name=employee_name).first()
                if not employee:
                    existing_count = Employee.query.count()
                    employee_code = f"EMP_{existing_count+1:03d}"
                    while Employee.query.filter_by(employee_code=employee_code).first():
                        existing_count += 1
                        employee_code = f"EMP_{existing_count+1:03d}"
                    
                    employee = Employee(name=employee_name, employee_code=employee_code)
                    db.session.add(employee)
                    db.session.flush()
                
                # æŸ¥æ‰¾æˆ–å‰µå»ºç­åˆ¥é¡å‹
                shift_type = ShiftType.query.filter_by(code=shift_code).first()
                if not shift_type:
                    shift_name, start_time, end_time, color = get_shift_info(shift_code)
                    shift_type = ShiftType(
                        code=shift_code,
                        name=shift_name,
                        start_time=start_time,
                        end_time=end_time,
                        color=color
                    )
                    db.session.add(shift_type)
                    db.session.flush()
                
                # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨æ’ç­è¨˜éŒ„
                existing_schedule = Schedule.query.filter_by(
                    date=schedule_date,
                    employee_id=employee.id
                ).first()
                
                if existing_schedule:
                    # æ›´æ–°ç¾æœ‰è¨˜éŒ„
                    existing_schedule.shift_type_id = shift_type.id
                    existing_schedule.updated_at = datetime.utcnow()
                    skipped_count += 1
                else:
                    # å‰µå»ºæ–°è¨˜éŒ„
                    schedule = Schedule(
                        date=schedule_date,
                        employee_id=employee.id,
                        shift_type_id=shift_type.id
                    )
                    db.session.add(schedule)
                    imported_count += 1
                
            except Exception as e:
                print(f'ç¬¬{index+2}è¡ŒåŒ¯å…¥éŒ¯èª¤: {e}')
                skipped_count += 1
                continue
        
        db.session.commit()
        return {'imported_count': imported_count, 'skipped_count': skipped_count}
        
    except Exception as e:
        db.session.rollback()
        raise e

def perform_data_import(df, validation_result):
    """åŸ·è¡Œå¯¦éš›è³‡æ–™åŒ¯å…¥ï¼ˆä¿ç•™å‘å¾Œå…¼å®¹æ€§ï¼‰"""
    imported_count = 0
    skipped_count = 0
    
    try:
        name_col, date_col, shift_col = identify_columns(df)
        
        for index, row in df.iterrows():
            try:
                # æå–è³‡æ–™
                employee_name = str(row[name_col]).strip()
                date_value = row[date_col]
                shift_code = str(row[shift_col]).strip()
                
                # è·³éç©ºç™½æˆ–ç„¡æ•ˆè³‡æ–™
                if not employee_name or not shift_code or pd.isna(date_value):
                    continue
                
                # è™•ç†æ—¥æœŸ
                if isinstance(date_value, str):
                    schedule_date = datetime.strptime(date_value, '%Y-%m-%d').date()
                else:
                    schedule_date = date_value.date() if hasattr(date_value, 'date') else date_value
                
                # æŸ¥æ‰¾æˆ–å‰µå»ºå“¡å·¥
                employee = Employee.query.filter_by(name=employee_name).first()
                if not employee:
                    existing_count = Employee.query.count()
                    employee_code = f"EMP_{existing_count+1:03d}"
                    while Employee.query.filter_by(employee_code=employee_code).first():
                        existing_count += 1
                        employee_code = f"EMP_{existing_count+1:03d}"
                    
                    employee = Employee(name=employee_name, employee_code=employee_code)
                    db.session.add(employee)
                    db.session.flush()
                
                # æŸ¥æ‰¾æˆ–å‰µå»ºç­åˆ¥é¡å‹
                shift_type = ShiftType.query.filter_by(code=shift_code).first()
                if not shift_type:
                    shift_name, start_time, end_time, color = get_shift_info(shift_code)
                    shift_type = ShiftType(
                        code=shift_code,
                        name=shift_name,
                        start_time=start_time,
                        end_time=end_time,
                        color=color
                    )
                    db.session.add(shift_type)
                    db.session.flush()
                
                # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨æ’ç­è¨˜éŒ„
                existing_schedule = Schedule.query.filter_by(
                    date=schedule_date,
                    employee_id=employee.id
                ).first()
                
                if existing_schedule:
                    # æ›´æ–°ç¾æœ‰è¨˜éŒ„
                    existing_schedule.shift_type_id = shift_type.id
                    existing_schedule.updated_at = datetime.utcnow()
                    skipped_count += 1
                else:
                    # å‰µå»ºæ–°è¨˜éŒ„
                    schedule = Schedule(
                        date=schedule_date,
                        employee_id=employee.id,
                        shift_type_id=shift_type.id
                    )
                    db.session.add(schedule)
                    imported_count += 1
                
            except Exception as e:
                print(f'ç¬¬{index+2}è¡ŒåŒ¯å…¥éŒ¯èª¤: {e}')
                continue
        
        db.session.commit()
        return {'imported_count': imported_count, 'skipped_count': skipped_count}
        
    except Exception as e:
        db.session.rollback()
        raise e